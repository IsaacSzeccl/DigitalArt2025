{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jqr64leiivfA"
      },
      "outputs": [],
      "source": [
        "# Please use a GPU (such as T4) on Google Colab to run the code\n",
        "# The images should be generated within a minute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIrgth7sqFML"
      },
      "outputs": [],
      "source": [
        "!pip install -q diffusers==0.11.1\n",
        "!pip install -q transformers scipy ftfy accelerate\n",
        "!pip install --upgrade huggingface-hub==0.26.2 transformers==4.46.1 tokenizers==0.20.1 diffusers==0.31.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMZJGHLJivfG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LA9myHTxbDhm"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device=torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device=torch.device(\"mps\")\n",
        "else:\n",
        "    device=torch.device(\"cpu\")\n",
        "pipe = pipe.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ8zJRcRivfI"
      },
      "outputs": [],
      "source": [
        "prompt = \"a photo of a group of people, with a green mountain background and large blue sky in cartoon style\"\n",
        "generator = torch.Generator(device).manual_seed(1000)\n",
        "# Change height, width to change the size of the image. Increasing the size will increase the time needed to generate the images.\n",
        "# Increase num_inference_steps to generate image of better quality, but will increase the time needed to generate the images.\n",
        "image = pipe(prompt, height=1024, width=1024, num_inference_steps=100, generator=generator).images[0]\n",
        "\n",
        "\n",
        "# Change test.png to save the image with a different name\n",
        "image.save(f\"test.png\")\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBmuGt3Vk9ia"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}